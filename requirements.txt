# Meta Kaggle Data Pipeline Requirements
# Install these packages in Airflow environment

# ===== Core Framework =====
apache-airflow>=3.0.4

# ===== Data Processing & Analytics =====
pyspark==3.5.0
pandas>=2.0.0
numpy>=1.24.0
pyarrow>=12.0.0
fastparquet>=2023.7.0

# ===== Configuration Management =====
pyyaml>=6.0
python-dotenv>=1.0.0

# ===== Data Quality & Testing =====
pytest>=7.0.0
pytest-spark>=0.6.0
chispa>=0.9.0
great-expectations>=0.17.0

# ===== Development & Debugging =====
ipython>=8.0.0
jupyter>=1.0.0

# ===== Optional: Advanced Analytics =====
scikit-learn>=1.3.0
scipy>=1.10.0

# ===== Optional: Visualization =====
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0

# ===== Optional: Delta Lake (Advanced features) =====
# delta-spark>=3.0.0

# ===== Production Optimization =====
# memory-profiler>=0.61.0
# psutil>=5.9.0

# ===== System Dependencies (for PySpark) =====
# Note: Java 11 JRE is installed in Dockerfile for PySpark support
# JAVA_HOME is set to /usr/lib/jvm/java-11-openjdk-amd64/

# ===== Note: Meta Kaggle Data Files =====
# Data files should be manually downloaded to data/meta/raw/
# - Datasets.csv
# - Competitions.csv 
# - Users.csv
# - Tags.csv
# - Kernels.csv
