# ğŸš€ Meta Kaggle Pipeline - Terraform Infrastructure

## ğŸ“‹ **OVERVIEW**

Complete **Infrastructure as Code** implementation cho Meta Kaggle ETL Pipeline sá»­ dá»¥ng **Medallion Architecture** (Raw â†’ Bronze â†’ Silver â†’ Gold) vá»›i:

- **AWS S3**: Data Lake storage vá»›i intelligent tiering
- **AWS Glue**: ETL jobs vÃ  Data Catalog
- **AWS Athena**: Interactive analytics workgroup
- **AWS Redshift Serverless**: Data warehouse vá»›i cost controls
- **IAM**: Comprehensive security vá»›i **auto-policy assignment**

## ğŸ—ï¸ **ARCHITECTURE**

```
â”Œâ”€â”€â”€ Raw Data (CSV) â”€â”€â”€â”    â”Œâ”€â”€â”€ Bronze Layer â”€â”€â”€â”    â”Œâ”€â”€â”€ Silver Layer â”€â”€â”€â”    â”Œâ”€â”€â”€ Gold Layer â”€â”€â”€â”
â”‚   â€¢ Meta datasets    â”‚ => â”‚  â€¢ Schema validationâ”‚ => â”‚  â€¢ Data cleaning   â”‚ => â”‚  â€¢ Business KPIs  â”‚
â”‚   â€¢ Competitions     â”‚    â”‚  â€¢ Metadata tags    â”‚    â”‚  â€¢ Deduplication   â”‚    â”‚  â€¢ Dimensional    â”‚
â”‚   â€¢ Users/Tags       â”‚    â”‚  â€¢ Partitioning     â”‚    â”‚  â€¢ Standardization â”‚    â”‚  â€¢ Fact tables    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš¡ **QUICK START**

### **1. Prerequisites**
```bash
# AWS CLI configured
aws configure list

# Terraform installed  
terraform version  # >= 1.0

# Proper permissions (auto-granted by deployment)
aws sts get-caller-identity
```

### **2. Deploy Infrastructure** 
```bash
cd terraform/environments/dev

# Review configuration
cat terraform.tfvars

# Initialize Terraform
terraform init

# Plan deployment (foundation + auto-permissions)
terraform plan -var-file='terraform.tfvars'

# Deploy complete infrastructure 
terraform apply -var-file='terraform.tfvars'
```

### **3. Verify Resources**
```bash
# Check S3 Data Lake
aws s3 ls s3://psi-de-glue-congdinh/

# Verify IAM permissions  
terraform output current_user_with_permissions

# List Glue resources (if deployed)
terraform output glue_databases
terraform output glue_crawlers
```

## ğŸ¯ **KEY FEATURES**

### **ğŸ” Automatic Permissions Management**
- **Self-granting IAM policy** tá»± Ä‘á»™ng Ä‘Æ°á»£c táº¡o vÃ  attach vÃ o current user
- KhÃ´ng cáº§n admin intervention hoáº·c manual script execution
- Full permissions cho Glue, Athena, Redshift Serverless

### **ğŸ›ï¸ Conditional Deployment**
```hcl
# Deploy only foundation (S3 + IAM)
auto_deploy_advanced_services = false

# Deploy complete pipeline (S3 + IAM + Glue + Redshift)  
auto_deploy_advanced_services = true
```

### **ğŸ’° Built-in Cost Controls**
- **Redshift Serverless**: 500 RPU-hours/month limit ($125-225 cap)
- **S3**: Intelligent tiering, lifecycle policies
- **Glue**: Optimized worker configurations
- **Monthly budget estimate**: $157-295

### **ğŸ”„ Production-Ready Patterns**
- **Idempotent operations**: Safe re-runs vá»›i Terraform state
- **Environment separation**: dev/staging/prod configurations
- **Comprehensive tagging**: Cost allocation, resource tracking
- **Security best practices**: Least privilege IAM policies

## ğŸ“ **DIRECTORY STRUCTURE**

```
terraform/
â”œâ”€â”€ environments/dev/           # Environment-specific config
â”‚   â”œâ”€â”€ main.tf                # Main deployment configuration
â”‚   â”œâ”€â”€ variables.tf           # Input variables with validation
â”‚   â”œâ”€â”€ outputs.tf             # Resource outputs
â”‚   â””â”€â”€ terraform.tfvars       # Environment values
â”œâ”€â”€ modules/                   # Reusable modules
â”‚   â”œâ”€â”€ s3/                   # Data Lake vá»›i Medallion structure  
â”‚   â”œâ”€â”€ iam/                  # Security + Auto-permissions
â”‚   â”œâ”€â”€ glue/                 # ETL jobs + Data Catalog
â”‚   â””â”€â”€ redshift/             # Serverless data warehouse
â”œâ”€â”€ init-backend.sh           # Remote state setup
â”œâ”€â”€ deploy.sh                 # Integrated deployment script
â””â”€â”€ README.md                 # This documentation
```

## ğŸ”§ **CONFIGURATION**

### **Core Variables** (`terraform.tfvars`)
```hcl
# Environment settings
environment = "dev"
aws_region  = "us-west-1"

# S3 Data Lake  
s3_bucket_name = "psi-de-glue-congdinh"

# Deployment control
auto_deploy_advanced_services = true    # Set false for foundation-only

# Redshift Serverless settings
redshift_base_capacity_rpus = 8
redshift_monthly_usage_limit = 500      # RPU-hours cap
```

### **Advanced Options**
```hcl
# Optional: Disable Secrets Manager
enable_secrets_manager = false

# Optional: Network configuration cho Redshift
publicly_accessible = false
private_subnet_ids = ["subnet-xxx", "subnet-yyy"] 
```

## ğŸ“Š **RESOURCE OUTPUTS**

```bash
# Foundation resources
terraform output s3_bucket_name
terraform output airflow_user_access_key_id

# Pipeline permissions  
terraform output meta_kaggle_pipeline_policy_arn
terraform output current_user_with_permissions

# Advanced services (if deployed)
terraform output glue_databases
terraform output redshift_namespace_name
terraform output redshift_estimated_monthly_cost
```

## ğŸš¨ **DEPLOYMENT SCENARIOS**

### **Scenario 1: Foundation First** 
```bash
# Set in terraform.tfvars
auto_deploy_advanced_services = false

terraform apply -var-file='terraform.tfvars'
# Deploys: S3 + IAM + Auto-permissions

# Later, deploy advanced services
auto_deploy_advanced_services = true
terraform apply -var-file='terraform.tfvars'  
```

### **Scenario 2: Complete Pipeline**
```bash
# Default: Full deployment 
terraform apply -var-file='terraform.tfvars'
# Deploys: S3 + IAM + Auto-permissions + Glue + Redshift
```

### **Scenario 3: Permission Issues**
```bash
# If admin permissions needed
terraform apply -target=module.iam
# Then retry full deployment
terraform apply -var-file='terraform.tfvars'
```

## ğŸ’¡ **BEST PRACTICES**

### **ğŸ·ï¸ Resource Tagging**
```hcl
common_tags = {
  Project     = "meta-kaggle-pipeline"
  Environment = "dev"
  ManagedBy   = "terraform"
  CostCenter  = "data-engineering"
  Owner       = "data-team"
}
```

### **ğŸ”’ Security**
- IAM policies follow **least privilege** principle
- Sensitive outputs marked as `sensitive = true`
- Resource-specific permissions vá»›i arn-based constraints

### **ğŸ’° Cost Management**
- Usage limits implemented for all chargeable services
- Automatic resource cleanup policies  
- Monthly cost estimation in outputs
- Intelligent storage tiering

## ğŸ› ï¸ **TROUBLESHOOTING**

### **Permission Denied Errors**
```bash
# The IAM policy should auto-grant permissions
# If still failing, check:
terraform output current_user_with_permissions

# Manual policy verification
aws iam list-attached-user-policies --user-name $(terraform output -raw current_user_with_permissions)
```

### **Glue Job Failures** 
```bash
# Check if advanced services deployed
terraform output glue_databases

# Verify S3 bucket access
aws s3 ls s3://$(terraform output -raw s3_bucket_name)/
```

### **State Management**
```bash
# Remote backend setup (optional)
./init-backend.sh

# State recovery
terraform import <resource> <id>
```

## ğŸ”„ **PIPELINE INTEGRATION**

### **Airflow Configuration**
```python
# Use Terraform outputs in Airflow DAGs
from airflow.models import Variable

BUCKET_NAME = Variable.get("S3_BUCKET_NAME", default_var="psi-de-glue-congdinh")
AWS_ACCESS_KEY_ID = Variable.get("AWS_ACCESS_KEY_ID")  # From terraform output
GLUE_ROLE_ARN = Variable.get("GLUE_ROLE_ARN")
```

### **Data Pipeline Flow**
1. **Raw ingestion** â†’ S3 raw/ folder
2. **Bronze jobs** â†’ Schema validation, metadata tagging  
3. **Silver jobs** â†’ Data cleaning, deduplication
4. **Gold jobs** â†’ Business metrics, dimensional modeling
5. **Analytics** â†’ Athena workgroup queries

## ğŸ¯ **PRODUCTION CHECKLIST**

- [ ] **Remote state**: Configure S3 backend vá»›i DynamoDB locking
- [ ] **Multiple environments**: Separate dev/staging/prod workspaces  
- [ ] **CI/CD integration**: Automate terraform plan/apply
- [ ] **Monitoring**: CloudWatch alarms cho resource usage
- [ ] **Backup strategy**: Cross-region replication cho critical data
- [ ] **Cost alerts**: Budget notifications setup
- [ ] **Security review**: IAM policies audit, VPC configuration

## ğŸ“ **SUPPORT**

### **Common Issues**
- **Resource limits**: Check AWS service quotas
- **Networking**: Ensure proper VPC/subnet configuration
- **Costs**: Monitor usage vá»›i AWS Cost Explorer

### **Documentation**
- **Terraform modules**: See individual module READMEs
- **AWS services**: Official AWS documentation  
- **Pipeline logic**: Check `dags/` directory trong Airflow project

---

**ğŸ’¡ This infrastructure follows enterprise patterns vá»›i production-ready configurations. Modify variables trong `terraform.tfvars` Ä‘á»ƒ customize cho specific requirements.**